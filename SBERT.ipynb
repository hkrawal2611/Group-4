{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10065908,"sourceType":"datasetVersion","datasetId":6203568},{"sourceId":10066187,"sourceType":"datasetVersion","datasetId":6203785},{"sourceId":10101914,"sourceType":"datasetVersion","datasetId":6230803},{"sourceId":184429,"sourceType":"modelInstanceVersion","modelInstanceId":157205,"modelId":179628}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-02T09:14:44.865554Z","iopub.execute_input":"2024-12-02T09:14:44.866384Z","iopub.status.idle":"2024-12-02T09:14:46.266477Z","shell.execute_reply.started":"2024-12-02T09:14:44.866336Z","shell.execute_reply":"2024-12-02T09:14:46.264845Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mred-dataset/full_data_info.txt\n/kaggle/input/bert-base/bert-base-uncased/tokenizer_config.json\n/kaggle/input/bert-base/bert-base-uncased/special_tokens_map.json\n/kaggle/input/bert-base/bert-base-uncased/vocab.txt\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_0_train.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_4_train.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_0_test.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_3_val.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_0_val.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_1_train.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_2_test.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_2_val.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_3_train.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_3_test.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_1_test.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_4_val.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_2_train.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_1_val.json\n/kaggle/input/nlp_model/transformers/default/1/argscichat_train_dev/fold_4_test.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModel, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import classification_report\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/nlp-dataset/nlp_dataset.csv')\n\n# Data Preparation: Select relevant columns\ndata = data[['hypothesis', 'premise', 'label']].dropna()\ndata['label'] = data['label'].map({'n': 0, 'c': 1})  # Map 'n' to 0 and 'c' to \ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:32.003404Z","iopub.execute_input":"2024-12-04T18:20:32.003917Z","iopub.status.idle":"2024-12-04T18:20:36.723773Z","shell.execute_reply.started":"2024-12-04T18:20:32.003860Z","shell.execute_reply":"2024-12-04T18:20:36.722600Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                          hypothesis  \\\n0  further the paper makes several misleading cla...   \n1  4 .i like the key idea and the speedup is very...   \n2  the idea to use sampling is nice but the analy...   \n3  to summarize i think this paper give some empi...   \n4  to summarize i think this paper give some empi...   \n\n                                             premise  label  \n0  the paper is rather well written but it strong...      0  \n1  review scores reflect this reviewers impressio...      0  \n2  review scores reflect this reviewers impressio...      0  \n3  in my opinion the overall quality of the paper...      0  \n4  the context and relevance as well as the contr...      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hypothesis</th>\n      <th>premise</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>further the paper makes several misleading cla...</td>\n      <td>the paper is rather well written but it strong...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4 .i like the key idea and the speedup is very...</td>\n      <td>review scores reflect this reviewers impressio...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the idea to use sampling is nice but the analy...</td>\n      <td>review scores reflect this reviewers impressio...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to summarize i think this paper give some empi...</td>\n      <td>in my opinion the overall quality of the paper...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>to summarize i think this paper give some empi...</td>\n      <td>the context and relevance as well as the contr...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:38.418626Z","iopub.execute_input":"2024-12-04T18:20:38.418969Z","iopub.status.idle":"2024-12-04T18:20:38.482760Z","shell.execute_reply.started":"2024-12-04T18:20:38.418940Z","shell.execute_reply":"2024-12-04T18:20:38.481111Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Split the data into train, validation, and test sets\ntrain_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:46.040122Z","iopub.execute_input":"2024-12-04T18:20:46.040976Z","iopub.status.idle":"2024-12-04T18:20:46.057803Z","shell.execute_reply.started":"2024-12-04T18:20:46.040937Z","shell.execute_reply":"2024-12-04T18:20:46.056704Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Dataset Class for DataLoader\nclass ReviewPairDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=128):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        inputs = self.tokenizer(\n            row['hypothesis'],\n            row['premise'],\n            add_special_tokens=True,\n            max_length=self.max_len,\n            truncation=True,\n            padding='max_length',\n            return_tensors=\"pt\"\n        )\n        return {\n            'input_ids': inputs['input_ids'].squeeze(0),\n            'attention_mask': inputs['attention_mask'].squeeze(0),\n            'label': torch.tensor(row['label'], dtype=torch.long)\n        }\n\n# Load pre-trained tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:50.086369Z","iopub.execute_input":"2024-12-04T18:20:50.087129Z","iopub.status.idle":"2024-12-04T18:20:50.773066Z","shell.execute_reply.started":"2024-12-04T18:20:50.087092Z","shell.execute_reply":"2024-12-04T18:20:50.772007Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"725e7284e32242249dfee9a166056a27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c09343e4df645f48a1aa90fc2cd5c79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3376fdd618304dc993267a186bd39b30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c9c32f7a33431bafe613c11377b0ef"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Create DataLoaders\ntrain_dataset = ReviewPairDataset(train_data, tokenizer)\nval_dataset = ReviewPairDataset(val_data, tokenizer)\ntest_dataset = ReviewPairDataset(test_data, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:54.264069Z","iopub.execute_input":"2024-12-04T18:20:54.264496Z","iopub.status.idle":"2024-12-04T18:20:54.269855Z","shell.execute_reply.started":"2024-12-04T18:20:54.264442Z","shell.execute_reply":"2024-12-04T18:20:54.268717Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:20:56.492898Z","iopub.execute_input":"2024-12-04T18:20:56.493253Z","iopub.status.idle":"2024-12-04T18:20:56.498716Z","shell.execute_reply.started":"2024-12-04T18:20:56.493220Z","shell.execute_reply":"2024-12-04T18:20:56.497614Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Model Definition\nclass ContrastiveClassifier(nn.Module):\n    def __init__(self, model_name, embedding_dim=384):\n        super(ContrastiveClassifier, self).__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.fc = nn.Linear(embedding_dim, 2)  # Binary classification\n\n    def forward(self, input_ids, attention_mask):\n        embeddings = self.encoder(input_ids, attention_mask)['pooler_output']\n        outputs = self.fc(embeddings)\n        return outputs\n\n# Instantiate the model\nmodel_name = \"sentence-transformers/all-MiniLM-L6-v2\"\nmodel = ContrastiveClassifier(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define Optimizer and Loss Function\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:21:25.844048Z","iopub.execute_input":"2024-12-04T18:21:25.844718Z","iopub.status.idle":"2024-12-04T18:21:26.298226Z","shell.execute_reply.started":"2024-12-04T18:21:25.844677Z","shell.execute_reply":"2024-12-04T18:21:26.297157Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\n# Training Function with TQDM and Timing\ndef train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=3):\n    for epoch in range(epochs):\n        start_time = time.time()  # Start timing the epoch\n        \n        # Training phase\n        model.train()\n        train_loss = 0\n        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1} Training\", leave=False)\n        \n        for batch in train_loader_tqdm:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n\n            # Update TQDM description with current batch loss\n            train_loader_tqdm.set_postfix(loss=loss.item())\n\n        avg_train_loss = train_loss / len(train_loader)\n        print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss:.4f}\")\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        val_preds, val_labels = [], []\n        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1} Validation\", leave=False)\n        \n        with torch.no_grad():\n            for batch in val_loader_tqdm:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['label'].to(device)\n\n                outputs = model(input_ids, attention_mask)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                preds = torch.argmax(outputs, dim=1)\n                val_preds.extend(preds.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n\n                # Update TQDM description with current batch loss\n                val_loader_tqdm.set_postfix(loss=loss.item())\n\n        avg_val_loss = val_loss / len(val_loader)\n        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n        print(classification_report(val_labels, val_preds))\n\n        # Calculate and print epoch time\n        end_time = time.time()\n        epoch_time = end_time - start_time\n        print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f} seconds\")\n\n# Train the Model\ntrain_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:30:34.309971Z","iopub.execute_input":"2024-12-04T18:30:34.310333Z","iopub.status.idle":"2024-12-04T18:37:29.398163Z","shell.execute_reply.started":"2024-12-04T18:30:34.310298Z","shell.execute_reply":"2024-12-04T18:37:29.397115Z"}},"outputs":[{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.1938\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3088\n              precision    recall  f1-score   support\n\n           0       0.92      0.95      0.94      6346\n           1       0.51      0.39      0.44       850\n\n    accuracy                           0.88      7196\n   macro avg       0.72      0.67      0.69      7196\nweighted avg       0.87      0.88      0.88      7196\n\nEpoch 1 completed in 138.27 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.1616\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3412\n              precision    recall  f1-score   support\n\n           0       0.92      0.94      0.93      6346\n           1       0.48      0.41      0.45       850\n\n    accuracy                           0.88      7196\n   macro avg       0.70      0.68      0.69      7196\nweighted avg       0.87      0.88      0.87      7196\n\nEpoch 2 completed in 138.40 seconds\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.1300\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.3609\n              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93      6346\n           1       0.47      0.48      0.47       850\n\n    accuracy                           0.87      7196\n   macro avg       0.70      0.70      0.70      7196\nweighted avg       0.87      0.87      0.87      7196\n\nEpoch 3 completed in 138.40 seconds\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), \"contrastive_classifier.pt\")\n\n# Inference on Test Data with TQDM\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    test_preds, test_labels = [], []\n    test_loader_tqdm = tqdm(test_loader, desc=\"Evaluating on Test Data\", leave=False)\n\n    with torch.no_grad():\n        for batch in test_loader_tqdm:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            preds = torch.argmax(outputs, dim=1)\n            test_preds.extend(preds.cpu().numpy())\n            test_labels.extend(labels.cpu().numpy())\n\n            # Optionally, display intermediate batch-level accuracy in the TQDM bar\n            batch_accuracy = (preds.cpu().numpy() == labels.cpu().numpy()).mean()\n            test_loader_tqdm.set_postfix(batch_accuracy=batch_accuracy)\n\n    print(\"Test Results:\")\n    print(classification_report(test_labels, test_preds))\n\n# Evaluate on Test Data\nevaluate_model(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:39:41.077343Z","iopub.execute_input":"2024-12-04T18:39:41.077841Z","iopub.status.idle":"2024-12-04T18:39:52.105063Z","shell.execute_reply.started":"2024-12-04T18:39:41.077804Z","shell.execute_reply":"2024-12-04T18:39:52.103987Z"}},"outputs":[{"name":"stderr","text":"                                                                                                \r","output_type":"stream"},{"name":"stdout","text":"Test Results:\n              precision    recall  f1-score   support\n\n           0       0.93      0.92      0.93      6313\n           1       0.47      0.48      0.47       884\n\n    accuracy                           0.87      7197\n   macro avg       0.70      0.70      0.70      7197\nweighted avg       0.87      0.87      0.87      7197\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}